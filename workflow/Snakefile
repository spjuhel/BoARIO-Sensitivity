# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.
configfile: "config/config.yaml"


from snakemake.utils import Paramspace
import pandas as pd


include: "rules/exio3_treatment.smk"
include: "rules/euregio_treatment.smk"
include: "rules/eora26_treatment.smk"
include: "rules/oecd_treatment.smk"


# include: "rule/plotting.smk"


wildcard_constraints:
    year="\d\d\d\d",
    aggregation="full_exio3compat|74_sectors",
    scope="general|local",
    focus="all_sim|no_absurd"

EXIO3_MRIOT = expand(
    "mrio-files/pkls/exiobase3/exiobase3_full_{year}_ixi.pkl", year=[2000, 2010]
)
ALL_MRIOT = (
    expand(
        "mrio-files/pkls/{mrio_type}/{mrio_type}_full_{year}.pkl",
        mrio_type=["euregio", "eora26", "oecd_v2021"],
        year=[2000, 2010],
    )
    + EXIO3_MRIOT
)

localrules: make_rst_report


rule all_mriot:
    input:
        ALL_MRIOT,


if config["testing"]:
    paramspace = Paramspace(
        pd.read_csv(config["parameters space test"]),
        filename_params=[
            "order",
            "psi",
            "base_alpha",
            "max_alpha",
            "tau_alpha",
        ],
    )
else:
    paramspace = Paramspace(
        pd.read_csv(config["parameters space"]),
        filename_params=[
            "order",
            "psi",
            "base_alpha",
            "max_alpha",
            "tau_alpha",
        ],
    )

rule make_rst_report:
    input:
        expand("report/source/results-pages/{focus}-results.rst", focus=config["focus"].keys())
    output:
        touch("report/report_pushed")
    conda:
        "envs/boario-sensi-report.yml"
    shell:
        """
        git add report/source;
        git add report/images;
        git commit -m "update results from workflow";
        git push;
        """

rule make_all_focus_results:
    input:
        local_rst=expand(
            "report/source/results-pages/results-contents/local-{{focus}}-{selection_type}-{faceting}-results.rst", selection_type=["recovery_sce"], faceting=["Experience~mrio"]
        ),
        general_rst=expand(
            "report/source/results-pages/results-contents/general-{{focus}}-{selection_type}-{faceting}-results.rst", selection_type=["cumsum_impact_class"], faceting=["sectorXregion~Experience"]
        ),
    params:
        variables=config["variables"],
    output:
        "report/source/results-pages/{focus}-results.rst",
    log:
        "logs/make_rst_{focus}-results.log",
    conda:
        "envs/boario-sensi-report.yml"
    script:
        "scripts/generate_results_index_rst.py"


def get_grids(wildcards):
    grids = []
    df_path=checkpoints.prep_plot_df.get(**wildcards).output[0]
    plot_df = pd.read_parquet(df_path)
    if config["focus"][wildcards.focus] != "all":
        plot_df.query(config["focus"][wildcards.focus], inplace=True)
    selections = plot_df[wildcards.selection_type].sort_values().unique()
    grids += expand(
        "{dirs}/{scope}/{focus}/{selection_type}~{selection}/{faceting}/{variable}_{plot_type}.{ext}",
        dirs=["results/figs", "report/images/figs"],
        scope=wildcards.scope,
        selection_type=wildcards.selection_type,
        selection=selections,
        focus=wildcards.focus,
        faceting=wildcards.faceting,
        variable=config["variables"],
        plot_type=config["plot config"]["plot types"],
        ext="svg",
    )
    return grids

rule make_rst_result:
    input:
        plot_df="results/{scope}-plot_df.parquet",
        grids=get_grids,
    output:
        res_rst="report/source/results-pages/results-contents/{scope}-{focus}-{selection_type}-{faceting}-results.rst"
    params:
        variables=config["variables"],
    log:
        "logs/make_rst_results-{scope}-{focus}-{selection_type}-{faceting}.log",
    conda:
        "envs/boario-sensi-report.yml"
    script:
        "scripts/generate_results_rst.py"

rule plot_grid:
    input:
        plot_df="results/{scope}-plot_df.parquet"
    output:
        expand(
            "{dirs}/{{scope}}/{{focus}}/{{selection_type}}~{{selection}}/{{faceting}}/{{variable}}_{{plot_type}}.{{ext}}",
            dirs=["results/figs", "report/images/figs"],
        ),
    params:
        sharey=config["plot config"]["grid"]["sharey"],
        row_order=config["plot config"]["grid"]["row order"],
    log:
        "logs/plot_results-{scope}-{focus}-{selection_type}-{selection}-{faceting}-{variable}-{plot_type}_{ext}.log",
    threads: 4
    resources:
        mem_mb=16000
    benchmark:
        "benchmarks/plot_results-{scope}-{focus}-{selection_type}-{selection}-{faceting}-{variable}-{plot_type}_{ext}.log"
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/plot_results.py"

checkpoint prep_plot_df:
    input:
        "results/common_aggreg.parquet",
    output:
        "results/{scope}-plot_df.parquet",
    log:
        "logs/prep_{scope}-plot_df.log",
    threads: 4
    resources:
        mem_mb=12000,
    benchmark:
        "benchmarks/prep_{scope}-plot_df.log"
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/prep_plot_df.py"


def regroup_input(wildcards):
    dico = {
        var: expand(
            "results/simulations/{params}/parquets/" + var + ".parquet",
            params=paramspace.instance_patterns,
        )
        for var in config["variables"]
    }
    return dico


rule regroup_parquet_to_common_aggreg:
    input:
        unpack(regroup_input),
        sectors_aggreg_ods=config["sectors_common_aggreg"],
        regions_aggreg_ods=config["regions_common_aggreg"],
    output:
        "results/common_aggreg.parquet",
    log:
        f"logs/regroup_aggreg.log",
    threads: 4
    benchmark:
        f"benchmarks/regroup_aggreg.log"
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/regroup_aggreg.py"


rule all_parquets:
    input:
        parquet_files=expand(
            "results/simulations/{params}/parquets/{var}.parquet",
            params=paramspace.instance_patterns,
            var=config["variables"],
        ),


def get_simulation_inputs(wildcards):
    mrio_name = wildcards.mrio
    sectors_scenario = wildcards.sectors_scenario
    filepath = "mrio-files/pkls/"  # the path to the pickle files
    regex = re.compile(
        r"^(oecd_v2021|euregio|exiobase3|eora26)_full_(\d{4})"
    )  # the regular expression to match filenames
    match = regex.match(mrio_name)  # match the filename with the regular expression
    if not match:
        raise ValueError(f"The file name {mrio_name} is not valid.")
    prefix, year = match.groups()  # get the prefix and year from the matched groups
    fullpath = filepath + prefix + "/" + mrio_name + ".pkl"  # create the full file path
    sectors_config_path = config["sectors_scenarios"][prefix + "_full"][
        sectors_scenario
    ]
    return {"mrio": fullpath, "sectors_config": sectors_config_path}


rule simulate:
    input:
        unpack(get_simulation_inputs),
    output:
        # format a wildcard pattern like "alpha~{alpha}/beta~{beta}/gamma~{gamma}"
        # into a file path, with alpha, beta, gamma being the columns of the data frame
        output_dir=directory(f"results/simulations/{paramspace.wildcard_pattern}"),
        parquet_files=[
            f"results/simulations/{paramspace.wildcard_pattern}/parquets/"
            + var
            + ".parquet"
            for var in config["variables"]
        ],
        json_files=[
            f"results/simulations/{paramspace.wildcard_pattern}/jsons/"
            + json
            + ".json"
            for json in [
                "indexes",
                "equilibrium_checks",
                "simulated_events",
                "simulated_params",
            ]
        ],
        #.format(paramspace.wildcard_pattern,"{files}"), files=["indexes","equilibrium_checks","simulated_events","simulated_params"]),
        done=touch(f"results/simulations/{paramspace.wildcard_pattern}/sim.done"),
    params:
        # automatically translate the wildcard values into an instance of the param space
        # in the form of a dict (here: {"alpha": ..., "beta": ..., "gamma": ...})
        simulation_params=paramspace.instance,
        sim_length=config["sim_length"],
    log:
        f"logs/simulations/{paramspace.wildcard_pattern}.log",
    threads: 4
    benchmark:
        f"benchmarks/simulations/{paramspace.wildcard_pattern}.log"
    resources:
        mem_mb=10000,
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/simulate.py"
