# Main entrypoint of the workflow.
# Please follow the best practices:
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there.
configfile: "config/config.yaml"


from snakemake.utils import Paramspace
import pandas as pd


include: "rules/exio3_treatment.smk"
include: "rules/euregio_treatment.smk"
include: "rules/eora26_treatment.smk"
include: "rules/oecd_treatment.smk"


# include: "rule/plotting.smk"


wildcard_constraints:
    year="\d\d\d\d",
    aggregation="full_exio3compat|74_sectors",

EXIO3_MRIOT = expand(
    "mrio-files/pkls/exiobase3/exiobase3_full_{year}_ixi.pkl", year=[2000, 2010]
)
ALL_MRIOT = (
    expand(
        "mrio-files/pkls/{mrio_type}/{mrio_type}_full_{year}.pkl",
        mrio_type=["euregio", "eora26", "oecd_v2021"],
        year=[2000, 2010],
    )
    + EXIO3_MRIOT
)


rule all_mriot:
    input:
        ALL_MRIOT,

if config["testing"]:
    paramspace = Paramspace(
        pd.read_csv(config["parameters space test"]),
        filename_params=[
            "order",
            "psi",
            "base_alpha",
            "max_alpha",
            "tau_alpha",
        ],
    )
else:
    paramspace = Paramspace(
        pd.read_csv(config["parameters space"]),
        filename_params=[
            "order",
            "psi",
            "base_alpha",
            "max_alpha",
            "tau_alpha",
        ],
    )

def get_grids(wildcards):
    grids = []
    bins = config["impacts_bins"].keys()
    for focus in config["focus"].keys():
        plot_df = pd.read_parquet(checkpoints.prep_plot_df.get(focus=focus).output)
        actual_classes = plot_df.max_neg_impact_class.unique()
        grids += expand("results/figs/sectors_regions_grids/{focus}/{impact_class}/{variable}_{plot_type}.{ext}", focus=focus, impact_class=actual_classes, variable=config["variables"], plot_type=config["plot config"]["plot types"], ext="svg")
    return grids

rule make_rst_report:
    input:
        get_grids
    output:
        "report/build/html/index.html"
    conda:
        "envs/boario-sensi-report.yml"
    shell:
        """
        cd report;
        make html;
        """

rule make_rst_results:
    input:
        dfs=expand("results/plot_df_{focus}.parquet", focus=config["focus"].keys()),
        grids=get_grids
    params:
        variables = config["variables"]
    output:
        "report/source/results.rst"
    log:
        "logs/make_rst_results.log",
    conda:
        "envs/boario-sensi-report.yml"
    script:
        "scripts/generate_results_rst.py"


rule all_grid:
    input:
        get_grids

rule plot_grid:
    input:
        "results/plot_df_{focus}.parquet",
    output:
        "results/figs/sectors_regions_grids/{focus}/{impact_class}/{variable}_{plot_type}.{ext}",
    params:
        sharey=config["plot config"]["grid"]["sharey"],
        row_order=config["plot config"]["grid"]["row order"]
    log:
        "logs/plot_results_{focus}_{impact_class}_{variable}_{plot_type}_{ext}.log",
    threads: 4
    benchmark:
        "benchmarks/plot_results_{focus}_{impact_class}_{variable}_{plot_type}_{ext}.log"
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/plot_results.py"

checkpoint prep_plot_df:
    input:
        "results/common_aggreg.parquet",
    output:
        "results/plot_df_{focus}.parquet"
    params:
        drop_dict=lambda wildcards: config["focus"][wildcards.focus]
    log:
        "logs/prep_plot_df_{focus}.log"
    threads: 4
    benchmark:
        "benchmarks/prep_plot_df_{focus}.log"
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/prep_plot_df.py"

def regroup_input(wildcards):
    dico = {
        var: expand(
            "results/simulations/{params}/parquets/" + var + ".parquet",
            params=paramspace.instance_patterns,
        )
        for var in config["variables"]
    }
    return dico


rule regroup_parquet_to_common_aggreg:
    input:
        unpack(regroup_input),
        sectors_aggreg_ods=config["sectors_common_aggreg"],
        regions_aggreg_ods=config["regions_common_aggreg"],
    output:
        "results/common_aggreg.parquet",
    log:
        f"logs/regroup_aggreg.log",
    threads: 4
    benchmark:
        f"benchmarks/regroup_aggreg.log"
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/regroup_aggreg.py"


rule all_parquets:
    input:
        parquet_files=expand(
            "results/simulations/{params}/parquets/{var}.parquet",
            params=paramspace.instance_patterns,
            var=config["variables"],
        ),


def get_simulation_inputs(wildcards):
    mrio_name = wildcards.mrio
    sectors_scenario = wildcards.sectors_scenario
    filepath = "mrio-files/pkls/"  # the path to the pickle files
    regex = re.compile(
        r"^(oecd_v2021|euregio|exiobase3|eora26)_full_(\d{4})"
    )  # the regular expression to match filenames
    match = regex.match(mrio_name)  # match the filename with the regular expression
    if not match:
        raise ValueError(f"The file name {mrio_name} is not valid.")
    prefix, year = match.groups()  # get the prefix and year from the matched groups
    fullpath = filepath + prefix + "/" + mrio_name + ".pkl"  # create the full file path
    sectors_config_path = config["sectors_scenarios"][prefix + "_full"][
        sectors_scenario
    ]
    return {"mrio": fullpath, "sectors_config": sectors_config_path}


rule simulate:
    input:
        unpack(get_simulation_inputs),
    output:
        # format a wildcard pattern like "alpha~{alpha}/beta~{beta}/gamma~{gamma}"
        # into a file path, with alpha, beta, gamma being the columns of the data frame
        output_dir=directory(f"results/simulations/{paramspace.wildcard_pattern}"),
        parquet_files=[
            f"results/simulations/{paramspace.wildcard_pattern}/parquets/"
            + var
            + ".parquet"
            for var in config["variables"]
        ],
        json_files=[
            f"results/simulations/{paramspace.wildcard_pattern}/jsons/"
            + json
            + ".json"
            for json in [
                "indexes",
                "equilibrium_checks",
                "simulated_events",
                "simulated_params",
            ]
        ],
        #.format(paramspace.wildcard_pattern,"{files}"), files=["indexes","equilibrium_checks","simulated_events","simulated_params"]),
        done=touch(f"results/simulations/{paramspace.wildcard_pattern}/sim.done"),
    params:
        # automatically translate the wildcard values into an instance of the param space
        # in the form of a dict (here: {"alpha": ..., "beta": ..., "gamma": ...})
        simulation_params=paramspace.instance,
        sim_length=config["sim_length"]
    log:
        f"logs/simulations/{paramspace.wildcard_pattern}.log",
    threads: 4
    benchmark:
        f"benchmarks/simulations/{paramspace.wildcard_pattern}.log"
    resources:
        mem_mb=10000
    conda:
        "envs/BoARIO-sensi.yml"
    script:
        "scripts/simulate.py"


# rule plot:
#     input:
#         f"results/simulations/{paramspace.wildcard_pattern}.csv"
#     output:
#         f"results/plots/{paramspace.wildcard_pattern}.pdf"
#     shell:
#         "touch {output}"
